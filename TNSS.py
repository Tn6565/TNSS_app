import os
import streamlit as st
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
import tweepy
from filelock import FileLock  # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒƒã‚¯è¿½åŠ 
from openai import OpenAI

# ====== åˆæœŸè¨­å®š ======

load_dotenv()  # .envã‹ã‚‰APIã‚­ãƒ¼ã‚’ç’°å¢ƒå¤‰æ•°ã«èª­ã¿è¾¼ã¿

# å„ç¨®APIã‚­ãƒ¼ã‚’os.environã‹ã‚‰å–å¾—
openai_api_key = os.environ.get("TN_SYSTEM")
consumer_key = os.environ.get("TNSS_API_KEY_for_X")
consumer_secret = os.environ.get("TNSS_API_SECRET_KEY_for_X")
access_token = os.environ.get("TNSS_ACCESS_TOKEN")
access_token_secret = os.environ.get("TNSS_API_SECRET_KEY_for_X")

# APIã‚­ãƒ¼æœªè¨­å®šæ™‚ã®ã‚¨ãƒ©ãƒ¼
if not all([openai_api_key, consumer_key, consumer_secret, access_token, access_token_secret]):
    st.error("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ç’°å¢ƒå¤‰æ•°ã¾ãŸã¯.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# LangChain(OpenAI) åˆæœŸåŒ–
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.9, openai_api_key=openai_api_key)

# Tweepy(X) åˆæœŸåŒ–
auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_token, access_token_secret)
api = tweepy.API(auth)

# åˆ©ç”¨åˆ¶é™
MAX_REQUESTS_PER_DAY = 15
counter_file = "request_counter.txt"
lock_file = counter_file + ".lock"  # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒƒã‚¯ç”¨

def read_count():
    with FileLock(lock_file):
        if not os.path.exists(counter_file):
            return 0
        with open(counter_file, "r") as f:
            return int(f.read().strip() or 0)

def write_count(count):
    with FileLock(lock_file):
        with open(counter_file, "w") as f:
            f.write(str(count))

today_count = read_count()

# ====== Streamlit UI ======
st.title("ğŸ“ X æŠ•ç¨¿æ”¯æ´ã‚¢ãƒ—ãƒª")
topic = st.text_input("æŠ•ç¨¿ã®ãƒˆãƒ”ãƒƒã‚¯ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:")

if "candidates" not in st.session_state:
    st.session_state.candidates = []

# ====== æŠ•ç¨¿æ–‡ç”Ÿæˆ ======
if st.button("å€™è£œã‚’ç”Ÿæˆã™ã‚‹", disabled=(today_count >= MAX_REQUESTS_PER_DAY)):
    if today_count >= MAX_REQUESTS_PER_DAY:
        st.error("âš ï¸ æœ¬æ—¥ã®æŠ•ç¨¿ä¸Šé™ï¼ˆ15ä»¶ï¼‰ã«é”ã—ã¾ã—ãŸã€‚")
    else:
        prompt = PromptTemplate(
            input_variables=["topic"],
            template="ä»¥ä¸‹ã®ãƒˆãƒ”ãƒƒã‚¯ã«ã¤ã„ã¦ã€ãƒ©ãƒ•ã§ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ãªå£èª¿ã§ã€140æ–‡å­—ä»¥å†…ã®æŠ•ç¨¿æ–‡ã‚’3ã¤ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\nãƒˆãƒ”ãƒƒã‚¯: {topic}",
        )
        chain = LLMChain(llm=llm, prompt=prompt)
        try:
            result = chain.run(topic=topic)
            # ç®‡æ¡æ›¸ãã‚„ç•ªå·ä»˜ãã«ã‚‚å¯¾å¿œ
            candidates = [c.lstrip("0123456789.ãƒ»- ").strip() for c in result.split("\n") if c.strip()]
            st.session_state.candidates = [c[:140] for c in candidates if c]
            st.success("âœ… æŠ•ç¨¿å€™è£œã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚")
        except Exception as e:
            st.error(f"ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

# ====== å€™è£œè¡¨ç¤ºã¨æŠ•ç¨¿ ======
if st.session_state.candidates:
    st.subheader("ç”Ÿæˆã•ã‚ŒãŸå€™è£œ")
    for i, c in enumerate(st.session_state.candidates, 1):
        st.write(f"{i}. {c}")
        post_btn = st.button(
            f"ã“ã®æŠ•ç¨¿ã‚’é€ä¿¡ã™ã‚‹ â†’ å€™è£œ {i}",
            key=f"post_{i}",
            disabled=(today_count >= MAX_REQUESTS_PER_DAY)
        )
        if post_btn:
            if today_count >= MAX_REQUESTS_PER_DAY:
                st.error("âš ï¸ æœ¬æ—¥ã®æŠ•ç¨¿ä¸Šé™ï¼ˆ15ä»¶ï¼‰ã«é”ã—ã¾ã—ãŸã€‚")
            else:
                try:
                    api.update_status(c)
                    st.success(f"âœ… æŠ•ç¨¿ã—ã¾ã—ãŸ: {c}")
                    today_count += 1
                    write_count(today_count)
                    st.info(f"æœ¬æ—¥ã®åˆ©ç”¨å›æ•°: {today_count}/{MAX_REQUESTS_PER_DAY}")
                except Exception as e:
                    st.error(f"æŠ•ç¨¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")